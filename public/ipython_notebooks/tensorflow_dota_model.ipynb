{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Dota Predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google's new [TensorFlow](https://www.tensorflow.org/) looks set to be the neural net library of the future, so I wanted to do a simple project to get to grips with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Dota matches is a fairly straight forward problem as far as neural nets go. Dota is a multiplayer online battle arena type game where two teams (Radiant and Dire) of 5 players try to destroy each others base. Each player can choose to play from a pool of 111 different characters (heros). Each character has a unique set of abilities and has a role to play in the game. This role is generally one of damage dealer, supportive, or something in between. The theory is that a successful team should be composed of characters whose roles and abilities work well together, and against the enemy team. The hope is that a neural would be able to pick up on these successful combinations and be able to predict the winner based on the characters picked by the players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem definition then is fairly straight forward. The input is a binary table of the the characters chosen by each team and the output is the winner of match, the Radiant team or the Dire team. However, its clear that there will be a large irreducible error, since individual player skill generally trumps character choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kevin Conley and Daniel Perry of Stanford University worked on a [paper](http://kevintechnology.com/post/71621133663/using-machine-learning-to-recommend-heroes-for) doing almost the same thing. Their paper focused on recommending characters for players to pick against an enemy line up. They train a logistic regression model to predict the winner of each match and use this to build a simple recommendation engine. Their best model gets to 69.8% validation accuracy. This seems like a solid result, its well above the 50% baseline, and supports the idea of large irreducible error as mentioned before. But lets try to replicate it anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When the authors gathered their dataset, there were 108 characters to choose from. Now there are 111, but I will continue using the out dated dataset for the sake of consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.720026078346\n",
      "MultinominalNB accuracy: 0.715616213512\n"
     ]
    }
   ],
   "source": [
    "#load and randomise data\n",
    "dataset = pd.read_csv('dota_dataset.csv', index_col = 0)\n",
    "dataset = dataset.take(np.random.permutation(len(dataset)))\n",
    "\n",
    "#split dependent/independent variables\n",
    "x = dataset.drop('radiant_win', axis=1)\n",
    "y = dataset['radiant_win']\n",
    "\n",
    "#print results\n",
    "print 'Logistic Regression accuracy:', np.mean(cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv = 2))\n",
    "print 'MultinominalNB accuracy:', np.mean(cross_val_score(MultinomialNB(), x, y, scoring='accuracy', cv = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something funnys going on in the paper, they report 69.8% accuracy using logistic regression but I have been unable to replicate it unless I restrict the dataset to the first ~20000 entries. This might suggest some error in the first ~20000 entries of the dataset. I compared logistic regression to my usual first choice for binary datasets, the multinomial Naive Bayes classifier. MultinomialNB seems to do much better over the whole dataset, and roughly in the ball park of the authors original model, so no harm done I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing our neural net model, it will be useful to use MultinomialNB as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First split our dataset into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (45918, 217) validation: (5670, 217) test: (5103, 217)\n"
     ]
    }
   ],
   "source": [
    "dataset, validation = train_test_split(dataset, test_size = 0.1)\n",
    "train, test = train_test_split(dataset, test_size = 0.1)\n",
    "print 'train:', train.shape, 'validation:', validation.shape, 'test:', test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the TensorFlow session. InteractiveSession works much better for iPython Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the placeholders. This are essentially all the information that you might want to pass into your graph. The reason for splitting up the x variable will be explained just a little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input/output placeholders\n",
    "x_dire    = tf.placeholder(\"float\", shape=[None, 108], name='x_dire')\n",
    "x_radiant = tf.placeholder(\"float\", shape=[None, 108], name='x_radiant')\n",
    "y_        = tf.placeholder(\"float\", shape=[None, 2], name='y_true')\n",
    "\n",
    "#we'll use dropout layers for regularisation which need a keep probability\n",
    "keep_prob1 = tf.placeholder(\"float\", name='keep_prob1')\n",
    "keep_prob2 = tf.placeholder(\"float\", name='keep_prob2')\n",
    "\n",
    "#there doesn't seem to be any other way to differenciate train and validation summaries for TensorBoard\n",
    "loss_name     = tf.placeholder(\"string\", name='loss_name')\n",
    "accuracy_name = tf.placeholder(\"string\", name='accuracy_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates a fully connected layer with the matching weights/biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_weight_bias(in_size, out_size):\n",
    "    initial_weight = tf.truncated_normal([in_size, out_size], stddev=0.2, mean=0.0)\n",
    "    initial_bias = tf.constant(0.1, shape=[out_size])\n",
    "    return tf.Variable(initial_weight), tf.Variable(initial_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll explain the network architecture. \n",
    "\n",
    "Since there are two teams in Dota and we intuitively want to network to first learn about the composition of each team, then pit them against each other, it makes sense to split the network in two at the bottom. One neural net to learn about the Radiant team, and another to learn about the Dire team, and combine them later to predict the winner. \n",
    "\n",
    "But a good team on the Radiant side is still be a good team on the Dire side. It makes sense that if our neural net model learns that a certain combination of characters on one side is a good it should transfer that knowledge to the other side. How do we do this? We make both sides use the same weights! This solves both problems. It allows the neural net to concentrate on learning what makes anyone one side effective at the lower layers and leaves how to combine that information to the higher levels. Its a nice hierarchical structure, which is exactly what neural nets are good at.\n",
    "\n",
    "We're going to project the output to 2 columns, which i'll explain below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first hero layer\n",
    "with tf.name_scope(\"hero_layers_1\") as scope:\n",
    "    W_hero1, b_hero1 = fc_weight_bias(108,80)      \n",
    "    #note that dire layer and radiant layer use the same weights and biases\n",
    "    dire_layer1 = tf.nn.relu(tf.matmul(x_dire, W_hero1) + b_hero1)\n",
    "    radiant_layer1 = tf.nn.relu(tf.matmul(x_radiant, W_hero1) + b_hero1)\n",
    "\n",
    "#second hero layer\n",
    "with tf.name_scope(\"hero_layers_2\") as scope:    \n",
    "    W_hero2, b_hero2 = fc_weight_bias(80,80)    \n",
    "    #again, dire and radiant use the same weights and biases\n",
    "    dire_layer2 = tf.nn.relu(tf.matmul(dire_layer1, W_hero2) + b_hero2)\n",
    "    radiant_layer2 = tf.nn.relu(tf.matmul(radiant_layer1, W_hero2) + b_hero2)\n",
    "\n",
    "#now concatenate the dire and radiant team outputs\n",
    "with tf.name_scope(\"hero_layers_concat\") as scope:\n",
    "    dire_radiant_concat = tf.concat(1, [dire_layer2, radiant_layer2])\n",
    "    dire_radiant_drop = tf.nn.dropout(dire_radiant_concat, keep_prob1)\n",
    "    h_drop1 = tf.nn.dropout(dire_radiant_drop, keep_prob1)\n",
    "    \n",
    "with tf.name_scope(\"hidden_layer_1\") as scope:\n",
    "    W_hidden1, b_hidden1 = fc_weight_bias(160,120)    \n",
    "    h_hidden1 = tf.nn.relu(tf.matmul(h_drop1, W_hidden1) + b_hidden1)\n",
    "    h_drop2 = tf.nn.dropout(h_hidden1, keep_prob2)\n",
    "\n",
    "with tf.name_scope(\"hidden_layer_2\") as scope:\n",
    "    W_hidden2, b_hidden2 = fc_weight_bias(120,75)    \n",
    "    h_hidden2 = tf.nn.relu(tf.matmul(h_drop2, W_hidden2) + b_hidden2)\n",
    "\n",
    "with tf.name_scope(\"hidden_layer_3\") as scope:\n",
    "    W_hidden3, b_hidden3 = fc_weight_bias(75,25)    \n",
    "    h_hidden3 = tf.nn.relu(tf.matmul(h_hidden2, W_hidden3) + b_hidden3)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"output_layer\") as scope:\n",
    "    W_hidden4, b_hidden4 = fc_weight_bias(25,2)    \n",
    "    y = tf.nn.softmax(tf.matmul(h_hidden3, W_hidden4) + b_hidden4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since we're using TensorFlow, we get a graph representation of our net for free! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/graph1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after propagating through the network, we need to analyse our result. As mentioned, our result will be project to two columns instead of just one. We'll one-hot encode the winning team so that one column represents a win for the Radiant and the other a win for the Dire. I got better preformance from the network doing softmax + cross-entropy on the two columns rather than sigmoid + binary cross-entropy on one column. I believe this might be because the network gets two points of information this way rather than one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve generalisation, I regularise the network by adding the sum of the l2 norms of all the weights and biases to the loss value. I found this helped a lot. Mean loss is used as a reporting metric to compare training and validation loss.\n",
    "\n",
    "For training, I used the Adam Optimizer. The best introductory resource I've found for choosing the right optimizer is by Sebastian Ruder [here](http://sebastianruder.com/optimizing-gradient-descent/). As he suggests, using an optimizer that implements adaptive learning rates for each parameter is usually advisable given sparse data. Since some heros are picked much less frequently than others, the Adam optimizer is a good choice here.\n",
    "\n",
    "Finally, for accuracy prediction, we pair off the prediction with the ground truth values to and check if they're equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss_calculations\") as scope:\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y + 1e-8))\n",
    "    weights_sum   = tf.add_n([tf.nn.l2_loss(variable) for variable in tf.all_variables()])\n",
    "    loss          = cross_entropy + weights_sum\n",
    "    mean_loss     = tf.reduce_mean(loss)\n",
    "\n",
    "with tf.name_scope(\"trainer\") as scope:\n",
    "    train_step    = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy_calculations\") as scope:\n",
    "    correct  = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow allows us to generate some nice visualisations in Tensorboard using summary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#summarize the accuracy and loss \n",
    "accuracy_summary = tf.scalar_summary(accuracy_name, accuracy)\n",
    "mean_loss_summary = tf.scalar_summary(loss_name, mean_loss)\n",
    "\n",
    "#summarize the distribution of output values\n",
    "y_hist = tf.histogram_summary(\"y\", y)\n",
    "\n",
    "#gather all summaries\n",
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "writer = tf.train.SummaryWriter(\"/home/mark/workspace/misc/dota-model/logdir\", sess.graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're just finished setting up our model, initialize all the variables we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a helper function to help create the various data feeds we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_feed(dataset, kp1=1.0, kp2=1.0, loss_str='loss', accuracy_str='accuracy'):\n",
    "    radiant_data, dire_data = dataset.ix[:,:108], dataset.ix[:,108:216]\n",
    "    winners = pd.get_dummies(dataset['radiant_win'])\n",
    "    return {\n",
    "        x_radiant: radiant_data,\n",
    "        x_dire: dire_data,\n",
    "        y_: winners,\n",
    "        loss_name: loss_str,\n",
    "        accuracy_name: accuracy_str,\n",
    "        keep_prob1: kp1,\n",
    "        keep_prob2: kp2\n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feed      = get_data_feed(train,      loss_str = 'loss_train',      accuracy_str = 'accuracy_train')\n",
    "validation_feed = get_data_feed(validation, loss_str = 'loss_validation', accuracy_str = 'accuracy_validation')\n",
    "test_feed       = get_data_feed(test,       loss_str = 'loss_test',       accuracy_str = 'accuracy_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a helper function to generate the mini-batches for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dataset, batch_size=512):\n",
    "    #randomise before every epoch\n",
    "    dataset = dataset.take(np.random.permutation(len(dataset)))\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(dataset):\n",
    "        yield dataset[i : i + batch_size]\n",
    "        i = i + batch_size           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 32321.9, train: 0.573196, validation: 0.575309\n",
      "epoch 1, loss: 31795.6, train: 0.583867, validation: 0.58642\n",
      "epoch 2, loss: 31684.5, train: 0.591794, validation: 0.589065\n",
      "epoch 3, loss: 31644.3, train: 0.594756, validation: 0.594709\n",
      "epoch 4, loss: 31583.8, train: 0.60301, validation: 0.60388\n",
      "epoch 5, loss: 31571.8, train: 0.605667, validation: 0.611287\n",
      "epoch 6, loss: 31535.8, train: 0.609108, validation: 0.611993\n",
      "epoch 7, loss: 31528.1, train: 0.610371, validation: 0.615344\n",
      "epoch 8, loss: 31512.9, train: 0.610763, validation: 0.616402\n",
      "epoch 9, loss: 31496.5, train: 0.611155, validation: 0.617637\n",
      "epoch 10, loss: 31473.7, train: 0.611264, validation: 0.617813\n",
      "epoch 11, loss: 31425.6, train: 0.611242, validation: 0.618166\n",
      "epoch 12, loss: 31401.9, train: 0.611198, validation: 0.618519\n",
      "epoch 13, loss: 31369.1, train: 0.611264, validation: 0.618519\n",
      "epoch 14, loss: 31348.2, train: 0.611307, validation: 0.618519\n",
      "epoch 15, loss: 31337.3, train: 0.611307, validation: 0.618519\n",
      "epoch 16, loss: 31291.3, train: 0.611307, validation: 0.618519\n",
      "epoch 17, loss: 31251.2, train: 0.611307, validation: 0.618519\n",
      "epoch 18, loss: 31220.9, train: 0.611307, validation: 0.618519\n",
      "epoch 19, loss: 31199.7, train: 0.611307, validation: 0.618519\n",
      "epoch 20, loss: 31159.8, train: 0.611307, validation: 0.618519\n",
      "epoch 21, loss: 31119.3, train: 0.611307, validation: 0.618519\n",
      "epoch 22, loss: 31095.9, train: 0.611307, validation: 0.618519\n",
      "epoch 23, loss: 31058.7, train: 0.611307, validation: 0.618519\n",
      "epoch 24, loss: 31013.1, train: 0.611307, validation: 0.618519\n",
      "epoch 25, loss: 30982, train: 0.611307, validation: 0.618519\n",
      "epoch 26, loss: 30926.9, train: 0.611307, validation: 0.618519\n",
      "epoch 27, loss: 30869, train: 0.611307, validation: 0.618519\n",
      "epoch 28, loss: 30783, train: 0.611307, validation: 0.618519\n",
      "epoch 29, loss: 30682.8, train: 0.611307, validation: 0.618519\n",
      "epoch 30, loss: 30555.5, train: 0.611307, validation: 0.618519\n",
      "epoch 31, loss: 30342.1, train: 0.611329, validation: 0.618519\n",
      "epoch 32, loss: 30084.5, train: 0.611372, validation: 0.618519\n",
      "epoch 33, loss: 29706.9, train: 0.614465, validation: 0.619929\n",
      "epoch 34, loss: 29213.9, train: 0.635067, validation: 0.641799\n",
      "epoch 35, loss: 28570.7, train: 0.669389, validation: 0.673192\n",
      "epoch 36, loss: 27966.5, train: 0.691994, validation: 0.691887\n",
      "epoch 37, loss: 27304.6, train: 0.69892, validation: 0.700353\n",
      "epoch 38, loss: 26818.7, train: 0.704909, validation: 0.699295\n",
      "epoch 39, loss: 26531.2, train: 0.707827, validation: 0.700176\n",
      "epoch 40, loss: 26255.7, train: 0.71105, validation: 0.700353\n",
      "epoch 41, loss: 26035.2, train: 0.712531, validation: 0.704056\n",
      "epoch 42, loss: 25903.3, train: 0.714208, validation: 0.705996\n",
      "epoch 43, loss: 25804.9, train: 0.714469, validation: 0.704586\n",
      "epoch 44, loss: 25732.4, train: 0.716582, validation: 0.705644\n",
      "epoch 45, loss: 25648.2, train: 0.71717, validation: 0.705644\n",
      "epoch 46, loss: 25575.6, train: 0.717083, validation: 0.706526\n",
      "epoch 47, loss: 25529.6, train: 0.718651, validation: 0.706702\n",
      "epoch 48, loss: 25489.4, train: 0.71926, validation: 0.707407\n",
      "epoch 49, loss: 25457.6, train: 0.719892, validation: 0.70776\n",
      "epoch 50, loss: 25431.7, train: 0.720959, validation: 0.708113\n",
      "epoch 51, loss: 25397.8, train: 0.720959, validation: 0.709347\n",
      "epoch 52, loss: 25374.6, train: 0.721569, validation: 0.708995\n",
      "epoch 53, loss: 25351.3, train: 0.721874, validation: 0.7097\n",
      "epoch 54, loss: 25336.9, train: 0.721939, validation: 0.708995\n",
      "epoch 55, loss: 25312.3, train: 0.721634, validation: 0.709524\n",
      "epoch 56, loss: 25302.5, train: 0.721743, validation: 0.709347\n",
      "epoch 57, loss: 25274.4, train: 0.722179, validation: 0.7097\n",
      "epoch 58, loss: 25269.1, train: 0.722179, validation: 0.709877\n",
      "epoch 59, loss: 25249.7, train: 0.722244, validation: 0.709171\n",
      "epoch 60, loss: 25232.6, train: 0.722418, validation: 0.710229\n",
      "epoch 61, loss: 25206.5, train: 0.722854, validation: 0.711287\n",
      "epoch 62, loss: 25200.6, train: 0.723485, validation: 0.710053\n",
      "epoch 63, loss: 25166.9, train: 0.723202, validation: 0.710406\n",
      "epoch 64, loss: 25156.1, train: 0.723398, validation: 0.710229\n",
      "epoch 65, loss: 25140.5, train: 0.723899, validation: 0.710229\n",
      "epoch 66, loss: 25129.5, train: 0.723943, validation: 0.711464\n",
      "epoch 67, loss: 25123.6, train: 0.724378, validation: 0.712522\n",
      "epoch 68, loss: 25104.4, train: 0.723921, validation: 0.711287\n",
      "epoch 69, loss: 25092.8, train: 0.724727, validation: 0.711817\n",
      "epoch 70, loss: 25091.4, train: 0.724683, validation: 0.711817\n",
      "epoch 71, loss: 25070.1, train: 0.724748, validation: 0.712522\n",
      "epoch 72, loss: 25070.6, train: 0.725075, validation: 0.711287\n",
      "epoch 73, loss: 25046.2, train: 0.724857, validation: 0.712169\n",
      "epoch 74, loss: 25055.1, train: 0.724966, validation: 0.711817\n",
      "epoch 75, loss: 25034.4, train: 0.725554, validation: 0.713404\n",
      "epoch 76, loss: 25029.3, train: 0.725075, validation: 0.712346\n",
      "epoch 77, loss: 25015.9, train: 0.72562, validation: 0.712875\n",
      "epoch 78, loss: 25012.4, train: 0.72562, validation: 0.711817\n",
      "epoch 79, loss: 25014, train: 0.725445, validation: 0.711287\n",
      "epoch 80, loss: 25005.5, train: 0.72575, validation: 0.71358\n",
      "epoch 81, loss: 24997.3, train: 0.725968, validation: 0.711464\n",
      "epoch 82, loss: 25002.2, train: 0.725663, validation: 0.712169\n",
      "epoch 83, loss: 24984.2, train: 0.725903, validation: 0.712522\n",
      "epoch 84, loss: 24978.5, train: 0.726251, validation: 0.712522\n",
      "epoch 85, loss: 24983.6, train: 0.726338, validation: 0.710758\n",
      "epoch 86, loss: 24951.5, train: 0.72612, validation: 0.711287\n",
      "epoch 87, loss: 24949.7, train: 0.725946, validation: 0.711111\n",
      "epoch 88, loss: 24948.8, train: 0.726186, validation: 0.711993\n",
      "epoch 89, loss: 24940.2, train: 0.72599, validation: 0.711993\n",
      "epoch 90, loss: 24927.3, train: 0.726142, validation: 0.712522\n",
      "epoch 91, loss: 24930.1, train: 0.726556, validation: 0.712169\n",
      "epoch 92, loss: 24922.1, train: 0.726425, validation: 0.712346\n",
      "epoch 93, loss: 24916.2, train: 0.726774, validation: 0.713228\n",
      "epoch 94, loss: 24909.1, train: 0.72697, validation: 0.713228\n",
      "epoch 95, loss: 24917.3, train: 0.726469, validation: 0.711111\n",
      "epoch 96, loss: 24897, train: 0.727144, validation: 0.711993\n",
      "epoch 97, loss: 24894.2, train: 0.727318, validation: 0.710406\n",
      "epoch 98, loss: 24885.2, train: 0.727427, validation: 0.711817\n",
      "epoch 99, loss: 24892.5, train: 0.727427, validation: 0.710935\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):    \n",
    "    for mini_batch in get_batches(train):\n",
    "        mini_batch_feed = get_data_feed(mini_batch, 0.5, 0.5)   \n",
    "        train_step.run(feed_dict = mini_batch_feed)\n",
    "    \n",
    "    #log every epoch\n",
    "    train_loss          = loss.eval(feed_dict = train_feed)\n",
    "    validation_loss     = loss.eval(feed_dict = validation_feed)\n",
    "\n",
    "    train_accuracy      = accuracy.eval(feed_dict = train_feed)\n",
    "    validation_accuracy = accuracy.eval(feed_dict = validation_feed)\n",
    "\n",
    "    train_summary_str      = merged.eval(feed_dict = train_feed)\n",
    "    validation_summary_str = merged.eval(feed_dict = validation_feed)                \n",
    "\n",
    "    writer.add_summary(train_summary_str, i)\n",
    "    writer.add_summary(validation_summary_str, i)\n",
    "    print(\"epoch %d, loss: %g, train: %g, validation: %g\"% (i, train_loss, train_accuracy, validation_accuracy)) \n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 or so epochs, it looks like the network has more or less converged. We also get some more pretty graphs for free from TensorBoard. Although its kinda annoying how there isn't currently anyway to put the training and validation loss plots on the same graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"files/loss.PNG\" style=\"width: 100%;\"/> </td>\n",
    "<td> <img src=\"files/accuracy.PNG\" style=\"width: 100%;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, only after we've convinced ourselves that our model is pretty much finalised, do we get to peek at the test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72212422"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval(feed_dict=test_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat, 72.21% test accuracy! Earlier, the MultinominalNB model got to about 71.5% accuracy. Before drawing the conclusion that our model is definitely better though, I think there are two things worth noting. \n",
    "\n",
    "The first is that there is a good chance we got kinda lucky with our test data and that it was relatively easy to predict. Its quite unusual to get a higher test score than validation score. This could be rectified by doing some proper cross validation, i.e repeatedly choosing different training, validation and test sets and seeing how the model preforms. But this is a bit of a chore when you have to worry about long training times.\n",
    "\n",
    "The second thing worth noting is the vast difference between the complexity of building each model. It is far from insignificant that the MultinominalNB model could be built and cross validated in one line of code. Its clear which one would be easier to maintain and debug. The added complexity of the neural net also brings the relative unexplainability of each decision. The naive bayes model can be analysed using some bayesian statistics, but analysing neural nets and understanding why they arrive at the answers they do is still an active area of research.\n",
    "\n",
    "Because of the points above, after all this, I think its fair to declare the one-line MultinominalNB model the winner. Either way, I learned a lot while writing this up which was always my primary goal. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
